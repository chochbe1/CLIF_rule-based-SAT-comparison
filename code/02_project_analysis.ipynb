{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import pyCLIF as pc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = pd.read_csv('../output/study_cohort.csv')\n",
    "\n",
    "# Ensure 'time_line' is in datetime format\n",
    "cohort['time_line'] = pd.to_datetime(cohort['time_line'])\n",
    "cohort['date'] = cohort['time_line'].dt.date\n",
    "\n",
    "# Sort the DataFrame by 'hospitalization_id' and 'date' to prepare for day numbering\n",
    "cohort = cohort.sort_values(['hospitalization_id', 'date'])\n",
    "\n",
    "# Assign day numbers to each 'hospitalization_id'\n",
    "cohort['day_number'] = cohort.groupby('hospitalization_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "# Create the combo_key by combining 'hospitalization_id' and 'day_number'\n",
    "cohort['hosp_id_day_key'] = cohort['hospitalization_id'].astype(str) + '_day_' + cohort['day_number'].astype(str)\n",
    "\n",
    "cohort['min_sedation_dose'] = cohort[['fentanyl', 'propofol', 'lorazepam', 'midazolam','hydromorphone','morphine']].min(axis=1, skipna=True)\n",
    "\n",
    "cohort = cohort.sort_values(by=['hosp_id_day_key', 'time_line']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cohort(df):\n",
    "    # Step 1: Fill forward the 'device_category' column within each 'hosp_id_day_key' group\n",
    "    df['device_category_ffill'] = df.groupby('hosp_id_day_key')['device_category'].ffill()\n",
    "    \n",
    "    # Step 2: Filter rows where 'time_line' is between 12 AM and 4 AM \n",
    "\n",
    "    mask_time = (df['time_line'].dt.hour >= 0) & (df['time_line'].dt.hour < 4)\n",
    "    df_filtered = df[mask_time]\n",
    "    \n",
    "    # Step 3: Group by 'hosp_id_day_key'\n",
    "    grouped = df_filtered.groupby('hosp_id_day_key')\n",
    "    \n",
    "    # Step 4: Define function to check if both conditions are met within each group\n",
    "    def conditions_met(group):\n",
    "        has_ivm = (group['device_category_ffill'].str.lower() == 'imv').any()\n",
    "        has_sedation = group['min_sedation_dose'].notna().any()\n",
    "        return has_ivm and has_sedation\n",
    "    \n",
    "    # Step 5: Apply the function to each group and filter groups that meet the conditions\n",
    "    filtered_groups = grouped.filter(lambda x: conditions_met(x))\n",
    "    \n",
    "    # Step 6: Get the list of unique 'hosp_id_day_key's that meet the conditions\n",
    "    result = filtered_groups['hosp_id_day_key'].unique()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "result = process_cohort(cohort)\n",
    "\n",
    "print('encounter_days with imv and sedation on from 12am to 4am : ',len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort['on_vent_and_sedation'] = 0\n",
    "cohort.loc[cohort['hosp_id_day_key'].isin(result), 'on_vent_and_sedation'] = 1\n",
    "\n",
    "# Ensure the data is sorted by 'hosp_id_day_key' and 'time_line'\n",
    "cohort = cohort.sort_values(by=['hosp_id_day_key', 'time_line']).reset_index(drop=True)\n",
    "\n",
    "# Forward-fill the 'rass' values within each 'hosp_id_day_key'\n",
    "cohort['rass_ffill'] = cohort.groupby('hosp_id_day_key')['rass'].ffill()\n",
    "\n",
    "# Fill forward the meds by hospitalization columns by 'hosp_id'\n",
    "cohort[['fentanyl', 'propofol', 'lorazepam', 'midazolam', 'hydromorphone', 'morphine']] = cohort.groupby('hospitalization_id')[\n",
    "    ['fentanyl', 'propofol', 'lorazepam', 'midazolam', 'hydromorphone', 'morphine']\n",
    "].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the dataset loaded into a DataFrame called cohort\n",
    "df = cohort.copy()  # Assuming cohort is already a Pandas DataFrame\n",
    "\n",
    "# Step 1: Create rank_sedation column\n",
    "# Initialize rank_sedation with NaN\n",
    "df['rank_sedation'] = np.nan\n",
    "\n",
    "# Step 1 Optimization: Use groupby and vectorized operations for rank assignment\n",
    "for hosp_id_day_key, hosp_data in tqdm(df[df['on_vent_and_sedation'] == 1].groupby('hosp_id_day_key'), desc='Processing hosp_id_day_keys'):\n",
    "    zero_mask = hosp_data['min_sedation_dose'] == 0\n",
    "    ranks = zero_mask.cumsum() * zero_mask\n",
    "    df.loc[hosp_data.index, 'rank_sedation'] = ranks.replace(0, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate all_meds_0_dose_1hr_forward, 30mins, and 1.5hr forward\n",
    "# Initialize the new columns with NaN to track rank values\n",
    "df['all_meds_0_dose_1hr_forward'] = np.nan\n",
    "df['all_meds_0_dose_30min_forward'] = np.nan\n",
    "df['all_meds_0_dose_1_5hr_forward'] = np.nan\n",
    "med_columns = ['fentanyl', 'propofol', 'lorazepam', 'midazolam', 'hydromorphone', 'morphine']\n",
    "\n",
    "# Step 2 Optimization: Use groupby and vectorized operations for meds check\n",
    "for hosp_id_day_key, hosp_data in tqdm(df[df['on_vent_and_sedation'] == 1].groupby('hosp_id_day_key'), desc='Processing hosp_id_day_keys for meds check'):\n",
    "    hosp_data_sorted = hosp_data.sort_values('time_line')\n",
    "    rank_counter_30min = 1\n",
    "    rank_counter_1hr = 1\n",
    "    rank_counter_1_5hr = 1\n",
    "    for index, row in hosp_data_sorted.iterrows():\n",
    "        if not np.isnan(row['rank_sedation']):\n",
    "            current_time = row['time_line']\n",
    "            # Define time windows\n",
    "            one_hour_forward = hosp_data_sorted[(hosp_data_sorted['time_line'] >= current_time) &\n",
    "                                                (hosp_data_sorted['time_line'] <= current_time + pd.Timedelta(hours=1))]\n",
    "            thirty_min_forward = hosp_data_sorted[(hosp_data_sorted['time_line'] >= current_time) &\n",
    "                                                  (hosp_data_sorted['time_line'] <= current_time + pd.Timedelta(minutes=30))]\n",
    "            one_half_hour_forward = hosp_data_sorted[(hosp_data_sorted['time_line'] >= current_time) &\n",
    "                                                     (hosp_data_sorted['time_line'] <= current_time + pd.Timedelta(hours=1, minutes=30))]\n",
    "            \n",
    "            # Check if all meds are zero for each timeframe and rank accordingly\n",
    "            if thirty_min_forward.empty or (thirty_min_forward[med_columns].isna() | (thirty_min_forward[med_columns] == 0)).all(axis=None):\n",
    "                df.at[index, 'all_meds_0_dose_30min_forward'] = rank_counter_30min\n",
    "                rank_counter_30min += 1\n",
    "\n",
    "            if one_hour_forward.empty or (one_hour_forward[med_columns].isna() | (one_hour_forward[med_columns] == 0)).all(axis=None):\n",
    "                df.at[index, 'all_meds_0_dose_1hr_forward'] = rank_counter_1hr\n",
    "                rank_counter_1hr += 1\n",
    "\n",
    "            if one_half_hour_forward.empty or (one_half_hour_forward[med_columns].isna() | (one_half_hour_forward[med_columns] == 0)).all(axis=None):\n",
    "                df.at[index, 'all_meds_0_dose_1_5hr_forward'] = rank_counter_1_5hr\n",
    "                rank_counter_1_5hr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate net improvement in rass_ffill for each segment using vectorized operations\n",
    "# Only calculate RASS if the corresponding forward column has a rank value\n",
    "df['rass_net_improvement_30min'] = np.nan\n",
    "df['rass_net_improvement_1hr'] = np.nan\n",
    "df['rass_net_improvement_1_5hr'] = np.nan\n",
    "\n",
    "def calculate_rass_net_improvement(group):\n",
    "    group = group.sort_values('time_line')\n",
    "    time_lines = group['time_line']\n",
    "    rass_values = group['rass_ffill']\n",
    "    \n",
    "    rass_30min_forward = rass_values.shift(-1).where((time_lines + pd.Timedelta(minutes=30)) >= time_lines)\n",
    "    rass_1hr_forward = rass_values.shift(-1).where((time_lines + pd.Timedelta(hours=1)) >= time_lines)\n",
    "    rass_1_5hr_forward = rass_values.shift(-1).where((time_lines + pd.Timedelta(hours=1, minutes=30)) >= time_lines)\n",
    "    \n",
    "    # Only calculate if there is a rank value for the respective forward columns\n",
    "    group['rass_net_improvement_30min'] = np.where(~group['all_meds_0_dose_30min_forward'].isna(), np.sign(rass_30min_forward - rass_values) * abs(rass_30min_forward - rass_values), np.nan)\n",
    "    group['rass_net_improvement_1hr'] = np.where(~group['all_meds_0_dose_1hr_forward'].isna(), np.sign(rass_1hr_forward - rass_values) * abs(rass_1hr_forward - rass_values), np.nan)\n",
    "    group['rass_net_improvement_1_5hr'] = np.where(~group['all_meds_0_dose_1_5hr_forward'].isna(), np.sign(rass_1_5hr_forward - rass_values) * abs(rass_1_5hr_forward - rass_values), np.nan)\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the optimized calculation using groupby and apply without dropping rows\n",
    "df = df.groupby('hosp_id_day_key').apply(lambda group: calculate_rass_net_improvement(group) if group['on_vent_and_sedation'].iloc[0] == 1 else group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('temp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=cohort\n",
    "\n",
    "# # Filter rows where 'time_line' is between 12 AM and 4 AM\n",
    "# mask_time = (df['time_line'].dt.hour >= 0) & (df['time_line'].dt.hour < 4)\n",
    "# df_filtered = df[mask_time]\n",
    "\n",
    "# # Get hospitalization_ids with 'ivm' in 'device_category' during this time\n",
    "# ids_with_ivm = df_filtered[df_filtered['device_category'].str.lower() == 'imv']['hospitalization_id'].unique()\n",
    "\n",
    "# # Get hospitalization_ids with at least one non-null 'is_sedation_recorded' during this time\n",
    "# ids_with_sedation = df_filtered[df_filtered['is_sedation_recorded'].notna()]['hospitalization_id'].unique()\n",
    "\n",
    "# # Find the intersection of both lists to get the final list of ids\n",
    "# ids_list = np.intersect1d(ids_with_ivm, ids_with_sedation)\n",
    "\n",
    "# print(\"List of hospitalization_ids meeting all conditions: \",len(ids_list))\n",
    "\n",
    "# ### flag those ids\n",
    "# cohort['on_vent_sedation'] = 0\n",
    "# cohort.loc[cohort['hospitalization_id'].isin(ids_list), 'on_vent_sedation'] = 1\n",
    "\n",
    "# # del df,mask_time,df_filtered,ids_with_ivm,ids_with_sedation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encounter eligible for sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = cohort[cohort['on_vent_sedation']==1].sort_values(by=['hospitalization_id', 'time_line']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort[cohort['hospitalization_id'] == 100178682307].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".satsbt_ATS24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
